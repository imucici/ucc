{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\USER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\USER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\USER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\USER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\USER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\USER\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\USER\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\USER\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\USER\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\USER\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\USER\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "# 安裝所需套件\n",
    "from sklearn import metrics\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from numpy import mean\n",
    "\n",
    "## EDA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "## 過採樣\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import BorderlineSMOTE\n",
    "from imblearn.over_sampling import SVMSMOTE\n",
    "from imblearn.over_sampling import ADASYN\n",
    "from imblearn.combine import SMOTETomek\n",
    "from imblearn.combine import SMOTEENN\n",
    "\n",
    "\n",
    "# 績效指標\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import classification_report,precision_score,recall_score,f1_score,roc_auc_score\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from collections import Counter\n",
    "\n",
    "## 建模\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "\n",
    "from sklearn import neighbors\n",
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from imblearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.datasets import make_classification\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    "df1 = pd.read_csv(\"C:/Users/USER/Desktop/firstphase_test.csv\")\n",
    "\n",
    "# 將與weather_delay無關的特徵刪除\n",
    "df1.drop([\"CRS_DEP_TIME\",\"DEP_TIME\",\"DEP_DELAY\",\"CRS_ARR_TIME\",\"ARR_TIME\",\"ARR_DELAY\"\n",
    "          ,\"CRS_ELAPSED_TIME\",\"ACTUAL_ELAPSED_TIME\",\"AIR_TIME\"],axis=1,inplace=True)\n",
    "\n",
    "\n",
    "#將target欄位移至最後一欄\n",
    "target_col = df1.pop(df1.columns[4])\n",
    "df1.insert(18, target_col.name, target_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 類別變數轉換\n",
    "# 值之間沒有大小的意義，用One-Hot(使用get_dummies)\n",
    "\n",
    "dummy = pd.get_dummies(df1[['ORIGIN','DEST']])\n",
    "\n",
    "\n",
    "# 將轉換後產生的dataframe塞入原始df1，並刪除ORIGIN、DEST\n",
    "df1 = pd.concat([dummy,df1],axis=1)\n",
    "df1.drop(['ORIGIN','DEST'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 由於features中有不用標準化的欄位(dummy)，加上標準化、split的返回結果是ndarray，\n",
    "## 因此要把不需要標準化的欄位獨立出來\n",
    "\n",
    "# 1.切分成訓練集、驗證集\n",
    "X = df1.iloc[:,:-1].values \n",
    "y = df1.iloc[:,-1].values\n",
    "\n",
    "X_trainval,X_test,y_trainval,y_test = train_test_split(X,y,test_size = 0.3,random_state = 1) \n",
    "\n",
    "# 2. 記錄不用標準化的欄位(type = dataframe)\n",
    "\n",
    "# ndarray to df\n",
    "Xtrainval = pd.DataFrame(X_trainval,columns = [str(i) for i in range(X_trainval.shape[1])])\n",
    "Xtest = pd.DataFrame(X_test,columns = [str(i) for i in range(X_test.shape[1])])\n",
    "\n",
    "## 目標df\n",
    "X_trainval_temp = Xtrainval[[\"0\",\"1\",\"2\",\"3\",\"4\",\"5\",'6',\"7\",\"8\",\"10\",\"11\"]]\n",
    "X_test_temp = Xtest[[\"0\",\"1\",\"2\",\"3\",\"4\",\"5\",'6',\"7\",\"8\",\"10\",\"11\"]]\n",
    "\n",
    "# 3. df to ndarray\n",
    "X_trainval_new = Xtrainval.to_numpy()\n",
    "X_test_new = Xtest.to_numpy()\n",
    "\n",
    "# 4. 標準化\n",
    "sc = StandardScaler().fit(X_trainval)\n",
    "x_train_std = sc.transform(X_trainval) ## 將規則用在訓練集\n",
    "x_test_std = sc.transform(X_test) ## 將規則用在測試集\n",
    "\n",
    "# 5. 將沒標準化的features放回df中\n",
    "xtrainval = pd.DataFrame(X_trainval,columns = [str(i) for i in range(X_trainval.shape[1])])\n",
    "xtest = pd.DataFrame(X_test,columns = [str(i) for i in range(X_test.shape[1])])\n",
    "\n",
    "xtrainval.drop([\"0\",\"1\",\"2\",\"3\",\"4\",\"5\",'6',\"7\",\"8\",\"10\",\"11\"],axis=1,inplace=True)\n",
    "xtest.drop([\"0\",\"1\",\"2\",\"3\",\"4\",\"5\",'6',\"7\",\"8\",\"10\",\"11\"],axis=1,inplace=True)\n",
    "\n",
    "del X_trainval\n",
    "del X_test\n",
    "\n",
    "X_trainval = pd.concat([X_trainval_temp,xtrainval],axis=1)\n",
    "X_test = pd.concat([X_test_temp,xtest],axis=1)\n",
    "\n",
    "# df to ndarray(為了進行SMOTE&CV)\n",
    "X_trainval = X_trainval.to_numpy()\n",
    "X_test = X_test.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0       0.96      1.00      0.98       554\n",
      "     class 1       0.00      0.00      0.00        21\n",
      "\n",
      "    accuracy                           0.96       575\n",
      "   macro avg       0.48      0.50      0.49       575\n",
      "weighted avg       0.93      0.96      0.95       575\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "##未進行補值前\n",
    "clf = RandomForestClassifier(max_depth=3, random_state=0)\n",
    "clf.fit(X_trainval, y_trainval)\n",
    "y_pred = clf.predict(X_test)\n",
    "target_names = ['class 0', 'class 1']\n",
    "print(classification_report(y_test, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset shape Counter({0: 1298, 1: 42})\n",
      "Resampled dataset shape Counter({0: 1298, 1: 1298})\n"
     ]
    }
   ],
   "source": [
    "## 確定補值成功\n",
    "print('Original dataset shape %s' % Counter(y_trainval))\n",
    "sm = SMOTE(random_state=42)\n",
    "X_res, y_res = sm.fit_resample(X_trainval, y_trainval)\n",
    "print('Resampled dataset shape %s' % Counter(y_res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0       0.99      0.82      0.90       554\n",
      "     class 1       0.15      0.86      0.26        21\n",
      "\n",
      "    accuracy                           0.82       575\n",
      "   macro avg       0.57      0.84      0.58       575\n",
      "weighted avg       0.96      0.82      0.88       575\n",
      "\n",
      "ROC AUC: 0.839\n"
     ]
    }
   ],
   "source": [
    "## 重跑一次RF\n",
    "clf = RandomForestClassifier(n_estimators=300, max_depth=4, random_state=0)\n",
    "clf.fit(X_res, y_res)\n",
    "y_pred = clf.predict(X_test)\n",
    "target_names = ['class 0', 'class 1']\n",
    "print(classification_report(y_test, y_pred, target_names=target_names))\n",
    "print('ROC AUC: %.3f' %roc_auc_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* SMOTE()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean ROC AUC: 0.905\n",
      "0.8621282447997248\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier(n_estimators=300, max_depth=4)\n",
    "over = SMOTE() \n",
    "\n",
    "steps = [('over', over), ('model', model)]\n",
    "pipeline = Pipeline(steps=steps)\n",
    "# evaluate pipeline\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "scores = cross_val_score(pipeline,X_trainval, y_trainval, scoring='roc_auc', cv=cv, n_jobs=-1)\n",
    "print('Mean ROC AUC: %.3f' % mean(scores))\n",
    "\n",
    "\n",
    "pipeline.fit(X_trainval, y_trainval)\n",
    "y_test_pred = pipeline.predict(X_test)\n",
    "print(roc_auc_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* SVMSMOTE()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean ROC AUC: 0.908\n",
      "0.8060426336599621\n"
     ]
    }
   ],
   "source": [
    "## xxxxx\n",
    "model = RandomForestClassifier(n_estimators=300, max_depth=4,random_state=1)\n",
    "over = SVMSMOTE() #BorderlineSMOTE() #SVMSMOTE() #ADASYN()\n",
    "under = RandomUnderSampler()\n",
    "steps = [('over', over), ('under', under), ('model', model)]\n",
    "pipeline = Pipeline(steps=steps)\n",
    "# evaluate pipeline\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "scores = cross_val_score(pipeline,X_trainval, y_trainval, scoring='roc_auc', cv=cv, n_jobs=-1)\n",
    "print('Mean ROC AUC: %.3f' % mean(scores))\n",
    "\n",
    "\n",
    "pipeline.fit(X_trainval, y_trainval)\n",
    "y_test_pred = pipeline.predict(X_test)\n",
    "print(roc_auc_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* BorderlineSMOTE()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BorderlineSMOTE():\n",
      "\n",
      "模型平均ROC AUC分數: 0.903\n",
      "測試集ROC AUC分數: 0.802\n",
      "----------------------------\n",
      "混淆矩陣:\n",
      "[[466  88]\n",
      " [  5  16]]\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier(n_estimators=300, max_depth=4)\n",
    "over = BorderlineSMOTE() \n",
    "under = RandomUnderSampler()\n",
    "steps = [('over', over), ('under', under), ('model', model)]\n",
    "pipeline = Pipeline(steps=steps)\n",
    "# evaluate pipeline\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "scores = cross_val_score(pipeline,X_trainval, y_trainval, scoring='roc_auc', cv=cv, n_jobs=-1)\n",
    "print(\"BorderlineSMOTE():\\n\")\n",
    "print('模型平均ROC AUC分數: %.3f' % mean(scores))\n",
    "\n",
    "pipeline.fit(X_trainval, y_trainval)\n",
    "y_test_pred = pipeline.predict(X_test)\n",
    "print(\"測試集ROC AUC分數: %.3f\" % roc_auc_score(y_test, y_test_pred))\n",
    "print(\"----------------------------\")\n",
    "print(\"混淆矩陣:\")\n",
    "print(confusion_matrix(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BorderlineSMOTE():\n",
      "\n",
      "模型平均ROC AUC分數: 0.904\n",
      "測試集ROC AUC分數: 0.803\n",
      "----------------------------\n",
      "混淆矩陣:\n",
      "[[468  86]\n",
      " [  5  16]]\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier(n_estimators=300, max_depth=4)\n",
    "over = BorderlineSMOTE() \n",
    "\n",
    "steps = [('over', over), ('model', model)]\n",
    "pipeline = Pipeline(steps=steps)\n",
    "# evaluate pipeline\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "scores = cross_val_score(pipeline,X_trainval, y_trainval, scoring='roc_auc', cv=cv, n_jobs=-1)\n",
    "print(\"BorderlineSMOTE():\\n\")\n",
    "print('模型平均ROC AUC分數: %.3f' % mean(scores))\n",
    "\n",
    "pipeline.fit(X_trainval, y_trainval)\n",
    "y_test_pred = pipeline.predict(X_test)\n",
    "print(\"測試集ROC AUC分數: %.3f\" % roc_auc_score(y_test, y_test_pred))\n",
    "print(\"----------------------------\")\n",
    "print(\"混淆矩陣:\")\n",
    "print(confusion_matrix(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ADASYN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADASYN():\n",
      "\n",
      "模型平均ROC AUC分數: 0.904\n",
      "測試集ROC AUC分數: 0.866\n",
      "----------------------------\n",
      "混淆矩陣:\n",
      "[[458  96]\n",
      " [  2  19]]\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier(n_estimators=300, max_depth=4)\n",
    "over = ADASYN() \n",
    "under = RandomUnderSampler()\n",
    "steps = [('over', over), ('under', under), ('model', model)]\n",
    "pipeline = Pipeline(steps=steps)\n",
    "# evaluate pipeline\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "scores = cross_val_score(pipeline,X_trainval, y_trainval, scoring='roc_auc', cv=cv, n_jobs=-1)\n",
    "print(\"ADASYN():\\n\")\n",
    "print('模型平均ROC AUC分數: %.3f' % mean(scores))\n",
    "\n",
    "pipeline.fit(X_trainval, y_trainval)\n",
    "y_test_pred = pipeline.predict(X_test)\n",
    "print(\"測試集ROC AUC分數: %.3f\" % roc_auc_score(y_test, y_test_pred))\n",
    "print(\"----------------------------\")\n",
    "print(\"混淆矩陣:\")\n",
    "print(confusion_matrix(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADASYN():\n",
      "\n",
      "模型平均ROC AUC分數: 0.903\n",
      "測試集ROC AUC分數: 0.864\n",
      "----------------------------\n",
      "混淆矩陣:\n",
      "[[456  98]\n",
      " [  2  19]]\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier(n_estimators=300, max_depth=4)\n",
    "over = ADASYN() \n",
    "\n",
    "steps = [('over', over), ('model', model)]\n",
    "pipeline = Pipeline(steps=steps)\n",
    "# evaluate pipeline\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "scores = cross_val_score(pipeline,X_trainval, y_trainval, scoring='roc_auc', cv=cv, n_jobs=-1)\n",
    "print(\"ADASYN():\\n\")\n",
    "print('模型平均ROC AUC分數: %.3f' % mean(scores))\n",
    "\n",
    "pipeline.fit(X_trainval, y_trainval)\n",
    "y_test_pred = pipeline.predict(X_test)\n",
    "print(\"測試集ROC AUC分數: %.3f\" % roc_auc_score(y_test, y_test_pred))\n",
    "print(\"----------------------------\")\n",
    "print(\"混淆矩陣:\")\n",
    "print(confusion_matrix(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* SMOTEENN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMOTEENN():\n",
      "\n",
      "模型平均ROC AUC分數: 0.901\n",
      "測試集ROC AUC分數: 0.851\n",
      "----------------------------\n",
      "混淆矩陣:\n",
      "[[442 112]\n",
      " [  2  19]]\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier(n_estimators=300, max_depth=4)\n",
    "over = SMOTEENN() \n",
    "\n",
    "steps = [('over', over), ('model', model)]\n",
    "pipeline = Pipeline(steps=steps)\n",
    "# evaluate pipeline\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "scores = cross_val_score(pipeline,X_trainval, y_trainval, scoring='roc_auc', cv=cv, n_jobs=-1)\n",
    "print(\"SMOTEENN():\\n\")\n",
    "print('模型平均ROC AUC分數: %.3f' % mean(scores))\n",
    "\n",
    "pipeline.fit(X_trainval, y_trainval)\n",
    "y_test_pred = pipeline.predict(X_test)\n",
    "print(\"測試集ROC AUC分數: %.3f\" % roc_auc_score(y_test, y_test_pred))\n",
    "print(\"----------------------------\")\n",
    "print(\"混淆矩陣:\")\n",
    "print(confusion_matrix(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* SMOTETomek()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMOTETomek():\n",
      "\n",
      "模型平均ROC AUC分數: 0.905\n",
      "測試集ROC AUC分數: 0.865\n",
      "----------------------------\n",
      "混淆矩陣:\n",
      "[[457  97]\n",
      " [  2  19]]\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier(n_estimators=300, max_depth=4,random_state=1)\n",
    "over = SMOTETomek() \n",
    "\n",
    "steps = [('over', over), ('model', model)]\n",
    "pipeline = Pipeline(steps=steps)\n",
    "# evaluate pipeline\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "scores = cross_val_score(pipeline,X_trainval, y_trainval, scoring='roc_auc', cv=cv, n_jobs=-1)\n",
    "print(\"SMOTETomek():\\n\")\n",
    "print('模型平均ROC AUC分數: %.3f' % mean(scores))\n",
    "\n",
    "pipeline.fit(X_trainval, y_trainval)\n",
    "y_test_pred = pipeline.predict(X_test)\n",
    "print(\"測試集ROC AUC分數: %.3f\" % roc_auc_score(y_test, y_test_pred))\n",
    "print(\"----------------------------\")\n",
    "print(\"混淆矩陣:\")\n",
    "print(confusion_matrix(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMOTETomek():\n",
      "\n",
      "模型平均ROC AUC分數: 0.905\n",
      "測試集ROC AUC分數: 0.862\n",
      "----------------------------\n",
      "混淆矩陣:\n",
      "[[454 100]\n",
      " [  2  19]]\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier(n_estimators=300, max_depth=4,random_state=1)\n",
    "over = SMOTETomek() \n",
    "\n",
    "steps = [('over', over), ('model', model)]\n",
    "pipeline = Pipeline(steps=steps)\n",
    "# evaluate pipeline\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "scores = cross_val_score(pipeline,X_trainval, y_trainval, scoring='roc_auc', cv=cv, n_jobs=-1)\n",
    "print(\"SMOTETomek():\\n\")\n",
    "print('模型平均ROC AUC分數: %.3f' % mean(scores))\n",
    "\n",
    "pipeline.fit(X_trainval, y_trainval)\n",
    "y_test_pred = pipeline.predict(X_test)\n",
    "print(\"測試集ROC AUC分數: %.3f\" % roc_auc_score(y_test, y_test_pred))\n",
    "print(\"----------------------------\")\n",
    "print(\"混淆矩陣:\")\n",
    "print(confusion_matrix(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
